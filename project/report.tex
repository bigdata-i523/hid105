\documentclass[sigconf]{acmart}
\input{format/i523}
\begin{document}

\title{Predictive Model For English Premier League Games}
\author{Josh Lipe-Melton}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{4400 E Sheffield Dr}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{jlipemel@umail.iu.edu}

\renewcommand{\shortauthors}{J. Lipe-Melton}

\begin{abstract}
We discuss a model for predicting the outcome of soccer matches based on the previous matches played by each team. The model we produce is based on a model discussed in a previous paper, which claims to predict match results extremely accurately based on the previous two meetings between the teams and the previous five matches between the teams. While the model we based the project on used a genetic tuning algorithm combined with a neural network, we attempted to use a multivariate regression model and a more basic neural network model, both from the sklearn package. The code for our model is in the project.ipynb file.
\end{abstract}

\keywords{sports, analytics, predictive, neural network, HID105, I523}

\maketitle

\section{Introduction}
Prediction of sporting events is an extremely difficult problem due to the enormous number of factors involved and the unpredictability of those factors. While a lot of data about sports is generated, it is still extremely difficult to create models which account for every factor involved. In the model we attempt to imitate, a match's result is hypothesized to be predictable based on the last five matches each team has played and the last two matches between the teams. The model we imitated created a three layer neural network using these features, and was initiated with weights created by a genetic tuning algorithm. The model we use loads data on the English Premier League, England's highest league and arguably the best league in the world. Using this data, we create features for each match based on the previous games played by those teams. In this way, we attempt to circumvent far more complicated methods of analyzing sports such as per possession models or spatial recognition and player tracking software. Common thought among soccer players indicates that a team's 'form', or how well they have played in their last five matches, is a significant indicator of how well a team will do in their next match. Similarly, it seems to follow common sense that if team 1 has beaten team 2 the previous two times they have played, that team 1 is likely to beat team 2 again the next time they play. 
There are many supporting factors to the assumption that a team that has beaten another repeatedly will do so again. For one, teams in the premier league with more money tend to do significantly better than those with less money. According to Gerhards, ''success in national football championships is highly predictable. The market value of a team is by far the most important single predictor''. \cite{MarketValue} In comparison to variables such as diversity of a team or the amount of turnover in team personnel, market value was far more positively correlated to success.
These facts seem to support the statement that plugging the form, or last five results of each team, and the previous results between the two teams, into some model, we could expect to predict with some consistency the results of soccer matches. Market value implies consistent success of some teams over others, which would seem to indicate that the previous two meetings between two teams should consistently correlate to results. Given previous results, some of the unpredictability of sporting events in general is taken away. While random chance should still certainly be accounted for, we expect significant correlation between previous match results and future match results.
In order to create models for predictive analytics, we used sklearn's python packages. The first is the multivariate linear regression model, which takes any number of variables and weights them according to their correlation to the true results. This model produces a continuous range of predictions. We also created a similar linear regression model using less features. Lastly, we created a neural network using the sklearn neural network package. This package takes an array of inputs, in this case match results, and produces layers of perceptrons, or 'neurons'. By combining multiple 'neurons' making use of stochastic gradient descent, more complicated problems and models can be represented than when using just one. Furthermore, ''The use of SGD In the neural network setting is motivated by the high cost of running back propagation over the full training set. SGD can overcome this cost and still lead to fast convergence.''\cite{StanfordSGD} Although sklearn offers various additional variables for tuning implementations of its neural network package, we chose not to use them in our code. This was due to a lack of experience tuning neural networks.

\section{Fuzzy Neural Network Model}
In a previous paper, we discussed a method of prediction solely uses past results to predict future results. In this method, a predictive model is based on the intuitive proposition that if team 1 has won their previous few games, team 2 has lost their previous few games, and team 1 has beaten team 2 the last two times they have played, team 1 will beat team 2 \cite{FuzzyModel}. The model proposed in this article assigns a value in the range [-5, 5] to the last five games played by each team as well as the last two games played between the two teams. The higher the number, the bigger the win. The lower the number, the bigger the loss. The predicted result of a game is a function of these numbers. Through a combination of a fuzzy logic table and a neural network algorithm, a result is predicted. First, the authors created a table with every possible value of x1-x12. Each of these combinations was then associated with a predicted result and a weight in the interval [0, 1] that indicated the confidence in the predicted result. These initial confidence intervals were then tuned. The predicted result is drawn from the range [Big loss (BL), Small loss (SL), Draw (D), Small win (SW), Big win (BW)] \cite{FuzzyModel}. Using a sample size of 1056 matches, the network assigned weights to the nodes in the neural network. The trained model was applied to 350 results from other seasons and was correct when predicting a big loss 91.4 percent of the time, a small loss 83.3 percent of the time, a draw 87 percent of the time, a small win 84 percent of the time, and a big win 94.6 percent of the time \cite{FuzzyModel}. The authors do cite flaws that come from not considering factors such as injured or suspended players, refereeing, or weather conditions \cite{FuzzyModel}.

Furthermore, this method's already impressive predictive accuracy could also be improved by taking into account strength of schedule, as a team that has narrowly won its last five games against very weak opponents would be favored against a team that has narrowly lost against very strong opponents. The machine learning techniques implemented in this study could have been improved by incorporating opponents' results into the model, giving more weight to wins against good teams. \cite{paper2} It would also be interesting to see whether using a continuous model would decrease the accuracy of predictions or give similar accuracy with more specificity than the fuzzy logic model. It seems possible that using the fuzzy logic model provides a neural network with more occurrences of samples that are similar to each other due to grouping results together, thereby providing a better prediction. In a continuous model, the features may be too varied for a neural network to pick up on without a greatly increased sample size.

\section{Project Model}
This project was an attempt to imitate the model discussed in the section 'Fuzzy Neural Network Model'. We used match data from http://www.football-data.co.uk \cite{SoccerData}. The data includes numerous statistics about English Premier League soccer matches dating back to 1993, including the team names and goals scored by each team, which were the data we were interested in. In order to load the data from the .csv files included in the website into a usable format, we used panda's read csv function. Three years of the data was in an unreadable format for the csv loader and was skipped in the analysis. We then narrowed the data down to the names of each team involved in each match and the number of goals scored by each team. We then created a function last5 to determine the last five matches the last team played, which returned the number of goals scored by the team minus the number of goals that had been scored on them. We also created a function prevMeetings to determine the results of the last two times the teams played. In each of these functions, we used goal difference to represent each result. Goal difference wsa found by subtracting the number of goals allowed in a match by the home team from the number of goals scored in a match by the home team. We kept individual match results within the range[-4, 4] in order to prevent very large wins or losses from having too much influence on the statistics. A 7-0 win, therefore, counted the same as a 4-0 win, and a 7-0 win followed by five losses couldn't result in a positive goal difference for the team. Next, we created a function sampler, which used prevMeetings and last5 to turn each row in the data into an array of the features about each match that we wanted. We referred to the last5 of the home team as 'z1', the last5 of the away team as 'z2', and the previous two meetings of the teams as 'z3' and 'z4' respectively in order to more consistently imitate the model discussed in the Fuzzy Neural Network Model. This model has the benefit of inherently giving value to the home team due to z1 always being the home team and z2 always being the away team. When two teams did not have previous results, z3 and z4 were entered as 0 and 0 so as not to affect the prediction either way. Because of this, we trimmed the first 250 results out of the data so as not to have too many z3 and z4 data points equal 0. When a team did not have five previous matches in the data, last5 returned a -5, as this typically indicates a team recently promoted to the league and therefore the team would not be expected to find much success. These functions slightly differed from the more complicated model we were imitating, as this used the last five results from each team as individual features in the first input layer of a neural network and the previous two meetings as input nodes in the second layer of a neural network. Furthermore, the model we were imitating used fuzzy logic to model the problem as a classification problem, using big loss, small loss, draw, big win, and small win as the classifications. Our model, however, attempts to create a continuous solution. In order to do so, we take the results of sampler as our sample data used for prediction and the output of another function, results, as our true data. Sklearn's linear multivariate linear regression model uses matrix algebra in order to create coefficients for each variable in the sample X. Each coefficient indicates the strength of the correlation between the variable in X and the actual result. Therefore, the coefficient is the weight which the variable is multiplied by when using the model to predict. Using sklearn's model, we fitted the sample data to the results and created an array of predictions, which we then compared to the true results.  We also used sklearn's neuralnetwork package to create a MLP Regressor neural network with the hidden layer sizes attribute set to 50, which we found to produce the smallest mean squared error. In order to reduce the bias towards z1 and z2, which are typically bigger in absolute value than z3 and z4, the data was scaled during preprocessing for this model. Next, the neural network fit the scaled data to the true results. Finally, evaluation of the model was done based on mean squared error between predictions and true results and percentages of correct predictions or predictions that were within a certain range of the true result. In our model, a correct prediction was classified as simply predicting within the same category as the result, with the categories being less than -.5, greater than .5, or in between .5 and -.5 goal difference, each representing a draw, home win, or home loss respectively. We also tested whether each prediction was within .5 or 1 of the true result.


\section{Evaluation}
\subsection{Efficiency}
Extraction of the data was relatively fast. The retrieveEPL function extracts 7832 rows of a dataframe relatively quickly. The last5 function is slow due to running 7832 times and checking a large portion of the dataframe for previous results each time. The sampler function is by far the slowest to run due to the large number of comparisons and indexes it has to do. Running last5 and prevMeetings on each row of the dataframe is less than quadratic time, but still ends up being extremely costly computationally. The results function runs in linear time, which is optimal. Finally, the models are fitted to the data extremely quickly as well.

\subsection{Prediction Performance}
The performance of the predictions was far less effective than the fuzzy neural network model we attempted to replicate. This was to be expected, however, as our model was simply a more basic version of the other model. In order to evaluate our model, we measure the mean squared error between the actual results and the predicted results of both the multivariate linear regression model and the neural network. Each had an almost identical mean squared error, with the neural network scoring 2.851 and the linear regression model scoring 2.868. Each model also had nearly identical proportions of games predicted within .5 of the correct result (.264 for the neural network and .263 for the multivariate linear regression model), games predicted within 1 of the correct result (.49 for both models), draws correctly predicted (.147 for the neural network and .144 for the multivariate linear regression model), home wins correctly predicted (.249 for the neural network and .255 for the multivariate linear regression model), home losses correctly predicted (.020 for the neural network and .019 for the multivariate linear regression model), and percent total correct predictions (.417 for the neural network and .419 for the multivariate linear regression model). The effect of z1 and z2 was as would be expected: z1 was a positive coefficient for the regressino model and z2 was negative. This indicates that the home team was favored, which was reflected in the mean value in both the prediction and true results sets being about 0.4. It was interesting to note, however, that the z3 and z4 features had almost no effect on the accuracy of the predictions. The linear regression model's coefficient for these two features was almost 0. This is extremely counter intuitive and could be a result of inserting 0 for z3 and z4 at times where no previous results could be found, although it seems that these should still be significant features for prediction. Both models' prediction sets' standard deviation was far lower than the actual results, which could be a significant factor in the mean squared error. After hypothesizing that this may have increased the number of home losses predicted correctly, we tried increasing the standard deviation. After subtracting the mean of each array from each element in the array, then multiplying each value by 1.76, the standard deviation of the true results, and adding the mean back to each element, the percent of correct results predicted increased to 45.00 and 45.50 percent for the multivariate linear regression model and neural network model respectively. Doing this, however, decreased the number of results predicted within .5 goals and 1 goal by about 7 percent for the multivariate linear regression model and by about 8 percent for the neural network model. This is most likely due to the fact that a large portion of soccer games end with a goal difference within 1 and -1, so pushing predictions farther from the mean reduces the number of predictions close to this range.

\subsection{Limitations}
In retrospect, it seems that the models' biggest flaws are both their lack of ability to incorporate the z3 and z4 features into their prediction. Going into the project, I had hypothesized that this should be the biggest indicator of which team would win, regardless of their play during their last five matches. This hypothesis was supported by the fuzzy neural network model we attempted to imitate as well. Furthermore, the repeated success of a handful of teams over the rest of the league would seem to indicate that a team that beats another team multiple times would continue to do so. This is due in large part to the fact that certain teams have far more money than others to spend on players, facilities, etc., and this does not typically change from year to year. Neither model in this project seemed to indicate that previous matches between teams had a significant affect on the match prediction. Common sense would therefore seem to indicate significant issues with the implementation of the model in our project. In future implementations, we could try a different way to handle cases where there are not two previous meetings between the teams. We could, for example, give the benefit of the doubt to the team that has been in the league the longest, as we did with the last5 function. It may also be that the hole in our data in the early two thousands could be significantly affecting that feature. The csv files for those years were significantly different and could not be processed with the same function used to load the data from the other years. This is another problem with our model, as it is based on data that is incomplete and skips three years. The model we attempted to imitate had a much smaller sample size (about 1000 compared to about 8000 for ours), but presumably had accurate data points for each sample. Finally, more work with tuning neural networks would be extremely helpful, as this is a first attempt at any sort of data analysis to this degree. More experience with setting up models and more knowledge of advanced statistics would presumably greatly strengthen a model such as this. It may also be helpful to take each season independently, as teams undergo significant change over the course of the offseason. In the model in this project, a team's first game of the season is predicted using the last five games from last season, which could have been a very different set of players. In the future, it could be useful to run comparisons between our project model and a model that ignored the first five games of the season for each team so as to ''get a feel'' for the way a team starts out the year instead of assuming they will pick up right where they left off from the season before. Further improvements could take into account other factors such as injuries, suspensions, refereeing or weather. Clearly, we were unable to replicate all facets of the other model. The genetic tuning was extremely complicated and tough to figure out, and the neural network had more sophisticated layers and tuning. Our sample size was greater, but the data was arguably less precise due to not having previous results for every game. Furthermore, breaking results down into categories using fuzzy logic could potentially enable the model to make more accurate predictions. The fuzzy logic is less specific than a prediction across a continuous range, but this could be a good thing when tuning or fitting a model because each permutation of potential inputs would be more likely to have been seen before a prediction is made. 
Another potential improvement could be to simply include more features. As indicated in the introduction, the financial value of a team is a significant indicator of a team's success, particularly in the premier league. According to \cite{TransferMarkt}, Chelsea is worth 631 million Euros, while Huddersfield Town is worth just 58 million. This great divide in value is seen consistently across top European leagues and could be a significant indicator of the results of matches due to the importance of being able to buy the best players. While this statistic could be partially accounted for in the previous two meetings between teams, it could be valuable to include it as its own feature in the predictive model. A potential problem would be the skyrocketing value of clubs over the last twenty years, as it would be difficult to scale the data appropriately before fitting the model.
Another feature to consider would be to augment the last five played and previous two meetings features in this model by taking into account the strength of schedule. For example, beating a team that was on a win streak would be more valuable than beating a team that had lost its last five games. This could be incorporated as a multiplier in the last5 and prevMeetings functions. In this way, more information could be included in the predictive model.

\section{Conclusion}
In the future it would be interesting to compare an improved model to gambling lines to see how different the results are and whether there were any patterns to predicted results differing from betting lines and actual results. It could be possible, for example, that if there is a big enough discrepancy between a model's predictions and a gambling line that it would actually be worth betting. As it is, the model is not nearly accurate enough to be used to reliably predict results of sporting events, as it only out predicts random chance by twelve percent. An improved model could potentially be used to set betting lines or to inform how to beat betting lines. As this was a first attempt at this sort of data analysis and the problem is quite complicated, this was a reasonable result. However, this is again not a model to be used for practical applications. It would be interesting to see how much more of the model in the example from paper 2 could be recreated. If a more accurate predictive model like this was created, it could potentially be used by soccer teams in order to predict which matches are more likely to be won or lost so as to determine which matches would be best to rest key players. A match that is predicted to be a three goal win for your team, for example, would be a much better game to rest a key player than a game predicted to be a draw. Furthermore, the model could be applied to other sports quite easily. By properly scaling data, data from sports such as football and basketball could put into the model and used in the same way. If the range for the goal difference of each game was changed, the theory behind the model could be tested for other sports as well. A future project could be to examine the difference in the correlation of past results in basketball or football versus soccer.

\section{Acknowledgements}
The author would like to thank Dr. Gregor von Laszewski and Juliette Zerick for their help throughout this course.

\bibliographystyle{plain}
\bibliography{report}
\end{document}
