\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Project}
\author{Josh Lipe-Melton}
\date{December 2017}

\begin{document}

\maketitle

\begin{abstract}
We discuss a model for predicting the outcome of soccer matches based on the previous matches played by each team. The model we produce is based on a model discussed in a previous paper, which claims to predict match results extremely accurately based on the previous two meetings between the teams and the previous five matches between the teams. While the model we based the project on used a neural network, we attempted to use a multivariate regression model and a more basic neural network model, both from the sklearn package.
\end{abstract}

\section{Introduction}
Prediction of sporting events is an extremely difficult problem due to the enormous number of factors involved and the unpredictability of those factors. While a lot of data about sports is generated, it is still extremely difficult to create models which account for every factor involved. In the model we attempt to imitate, a match's result is hypothesized to be predictable based on the last five matches each team has played and the last two matches between the teams. The model we imitated created a three layer neural network using these features, and was initiated with weights created by a genetic tuning algorithm. The model we use loads data on the English Premier League, England's highest league and arguably the best league in the world. Using this data, we create features for each match based on the previous games played by those teams. In this way, we attempt to circumvent far more complicated methods of analyzing sports such as per possession models or spatial recognition and player tracking software. Common thought among soccer players indicates that a team's 'form', or how well they have played in their last five matches, is a significant indicator of how well a team will do in their next match. Similarly, it seems to follow common sense that if team 1 has beaten team 2 the previous two times they have played, that team 1 is likely to beat team 2 again the next time they play. By plugging these features into some model, we could expect that some credibility could be found in the prediction of the model based on our degree of confidence in the common sense assumptions above.

\section{Fuzzy Neural Network Model}
In a previous paper, we discussed a method of prediction solely uses past results to predict future results. In this method, a predictive model is based on the intuitive proposition that if team 1 has won their previous few games, team 2 has lost their previous few games, and team 1 has beaten team 2 the last two times they have played, team 1 will beat team 2 \cite{FuzzyModel}. The model proposed in this article assigns a value in the range [-5, 5] to the last five games played by each team as well as the last two games played between the two teams. The higher the number, the bigger the win. The lower the number, the bigger the loss. The predicted result of a game is a function of these numbers. Through a combination of a fuzzy logic table and a neural network algorithm, a result is predicted. First, the authors created a table with every possible value of x1-x12. Each of these combinations was then associated with a predicted result and a weight in the interval [0, 1] that indicated the confidence in the predicted result. These initial confidence intervals were then tuned. The predicted result is drawn from the range [Big loss (BL), Small loss (SL), Draw (D), Small win (SW), Big win (BW)] \cite{FuzzyModel}. Using a sample size of 1056 matches, the network assigned weights to the nodes in the neural network. The trained model was applied to 350 results from other seasons and was correct when predicting a big loss 91.4 percent of the time, a small loss 83.3 percent of the time, a draw 87 percent of the time, a small win 84 percent of the time, and a big win 94.6 percent of the time \cite{FuzzyModel}. The authors do cite flaws that come from not considering factors such as injured or suspended players, refereeing, or weather conditions \cite{FuzzyModel}.

Furthermore, this method's already impressive predictive accuracy could also be improved by taking into account strength of schedule, as a team that has narrowly won its last five games against very weak opponents would be favored against a team that has narrowly lost against very strong opponents. The machine learning techniques implemented in this study could have been improved by incorporating opponents' results into the model, giving more weight to wins against good teams. \cite{paper2} It would also be interesting to see whether using a continuous model would decrease the accuracy of predictions or give similar accuracy with more specificity than the fuzzy logic model. It seems possible that using the fuzzy logic model provides a neural network with more occurrences of samples that are similar to each other due to grouping results together, thereby providing a better prediction. In a continuous model, the features may be too varied for a neural network to pick up on without a greatly increased sample size.

\section{Project Model}
This project was an attempt to imitate the model discussed in the section 'Fuzzy Neural Network Model'. We used match data from http://www.football-data.co.uk \cite{SoccerData}. The data includes numerous statistics about English Premier League soccer matches dating back to 1993, including the team names and goals scored by each team, which were the data we were interested in. In order to load the data from the .csv files included in the website into a usable format, we used panda's read csv function. Three years of the data was in an unreadable format for the csv loader and was skipped in the analysis. We then narrowed the data down to the names of each team involved in each match and the number of goals scored by each team. We then created a function last5 to determine the last five matches the last team played, which returned the number of goals scored by the team minus the number of goals that had been scored on them. We also created a function prevMeetings to determine the results of the last two times the teams played. In each of these functions, we used goal difference to represent each result. Goal difference wsa found by subtracting the number of goals allowed in a match by the home team from the number of goals scored in a match by the home team. We kept individual match results within the range[-4, 4] in order to prevent very large wins or losses from having too much influence on the statistics. A 7-0 win, therefore, counted the same as a 4-0 win, and a 7-0 win followed by five losses couldn't result in a positive goal difference for the team. Next, we created a function sampler, which used prevMeetings and last5 to turn each row in the data into an array of the features about each match that we wanted. We referred to the last5 of the home team as 'z1', the last5 of the away team as 'z2', and the previous two meetings of the teams as 'z3' and 'z4' respectively in order to more consistently imitate the model discussed in the Fuzzy Neural Network Model. When two teams did not have previous results, z3 and z4 were entered as 0 and 0 so as not to affect the prediction either way. Because of this, we trimmed the first 250 results out of the data so as not to have too many z3 and z4 data points equal 0. When a team did not have five previous matches in the data, last5 returned a -5, as this typically indicates a team recently promoted to the league and therefore the team would not be expected to find much success. These functions slightly differed from the more complicated model we were imitating, as this used the last five results from each team as individual features in the first input layer of a neural network and the previous two meetings as input nodes in the second layer of a neural network. Furthermore, the model we were imitating used fuzzy logic to model the problem as a classification problem, using big loss, small loss, draw, big win, and small win as the classifications. Our model, however, attempts to create a continuous solution. In order to do so, we take the results of sampler as our sample data used for prediction and the output of another function, results, as our true data. Using sklearn's linear regression model, we fitted the sample data to the results and created an array of predictions, which we then compared to the true results. We also used sklearn's neuralnetwork package to create a MLP Regressor neural network with the hidden layer sizes attribute set to 50, which we found to produce the smallest mean squared error. In order to reduce the bias towards z1 and z2, which are typically bigger than z3 and z4, the data was scaled during preprocessing for this model. Next, the neural network fit the scaled data to the true results. Finally, evaluation of the model was done based on mean squared error between predictions and true results and percentages of correct predictions or predictions that were within a certain range of the true result. In our model, a correct prediction was classified as simply predicting within the same category as the result, with the categories being less than -.5, greater than .5, or in between .5 and -.5 goal difference.

\section{Evaluation}
\subsection{Efficiency}
Extraction of the data was relatively fast. The retrieveEPL function extracts 7832 rows of a dataframe relatively quickly. The last5 function is slow due to running 7832 times and checking a large portion of the dataframe for previous results each time. The sampler function is by far the slowest to run due to the large number of comparisons and indexes it has to do. Running last5 and prevMeetings on each row of the dataframe is less than quadratic time, but still ends up being extremely costly. The results function runs in linear time, which is optimal. Finally, the models are fitted to the data extremely quickly as well.

\subsection{Prediction Performance}
The performance of the predictions was far less effective than the fuzzy neural network model we attempted to replicate. This was to be expected, however, as our model was simply a more basic version of the other model. In order to evaluate our model, we measure the mean squared error between the actual results and the predicted results of both the multivariate linear regression model and the neural network. Each had an almost identical mean squared error, with the neural network scoring 2.851 and the linear regression model scoring 2.868. Each model also had nearly identical proportions of games predicted within .5 of the correct result (.264 for the neural network and .263 for the multivariate linear regression model), games predicted within 1 of the correct result (.49 for both models), draws correctly predicted (.147 for the neural network and .144 for the multivariate linear regression model), home wins correctly predicted (.249 for the neural network and .255 for the multivariate linear regression model), home losses correctly predicted (.020 for the neural network and .019 for the multivariate linear regression model), and percent total correct predictions (.417 for the neural network and .419 for the multivariate linear regression model). It was interesting to note that the z3 and z4 features had almost no effect on the accuracy of the predictions. The linear regression model's coefficient for these two features was almost 0. This is extremely counter intuitive and could be a result of inserting 0 for z3 and z4 at times where no previous results could be found, although it seems that these should still be significant features for prediction. Both models' prediction sets' standard deviation was far lower than the actual results, which could be a significant factor in the mean squared error. After hypothesizing that this may have increased the number of home losses predicted correctly, we tried increasing the standard deviation. After subtracting the mean of each array from each element in the array, then multiplying each value by 1.76, the standard deviation of the true results, and adding the mean back to each element, the percent of correct results predicted increased to 45.00 and 45.50 percent for the multivariate linear regression model and neural network model respectively. Doing this, however, decreased the number of results predicted within .5 goals and 1 goal by about 7 percent for the multivariate linear regression model and by about 8 percent for the neural network model. This is most likely due to the fact that a large portion of soccer games end with a goal difference within 1 and -1, so pushing predictions farther from the mean reduces the number of predictions close to this range.

\subsection{Improvements}
In retrospect, it seems that the models' biggest flaws are both their lack of ability to incorporate the z3 and z4 features into their prediction. Going into the project, I had hypothesized that this should be the biggest indicator of which team would win, regardless of their play during their last five matches. This hypothesis was supported by the fuzzy neural network model we attempted to imitate as well. Furthermore, the repeated success of a handful of teams over the rest of the league would seem to indicate that a team that beats another team multiple times would continue to do so. This is due in large part to the fact that certain teams have far more money than others to spend on players, facilities, etc., and this does not typically change from year to year. Neither model in this project seemed to indicate that previous matches between teams had a significant affect on the match prediction. Common sense would therefore seem to indicate significant issues with the implementation of the model in our project. In future implementations, we could try a different way to handle cases where there are not two previous meetings between the teams. We could, for example, give the benefit of the doubt to the team that has been in the league the longest, as we did with the last5 function. It may also be that the hole in our data in the early two thousands could be significantly affecting that feature. The csv files for those years were significantly different and could not be processed with the same function used to load the data from the other years. This is another problem with our model, as it is based on data that is incomplete and skips three years. The model we attempted to imitate had a much smaller sample size (about 1000 compared to about 8000 for ours), but presumably had accurate data points for each sample. Finally, more work with tuning neural networks would be extremely helpful, as this is a first attempt at any sort of data analysis to this degree. More experience with setting up models and more knowledge of advanced statistics would presumably greatly strengthen a model such as this. It may also be helpful to take each season independently, as teams undergo significant change over the course of the offseason. In the model in this project, a team's first game of the season is predicted using the last five games from last season, which could have been a very different set of players. In the future, it could be useful to run comparisons between our project model and a model that ignored the first five games of the season for each team so as to ''get a feel'' for the way a team starts out the year instead of assuming they will pick up right where they left off from the season before. Further improvements could take into account other factors such as injuries, suspensions, refereeing or weather. Clearly, we were unable to replicate all facets of the other model. The genetic tuning was extremely complicated and tough to figure out, and the neural network had more sophisticated layers and tuning. Our sample size was greater, but the data was arguably less precise due to not having previous results for every game. Furthermore, breaking results down into categories using fuzzy logic could potentially enable the model to make more accurate predictions. The fuzzy logic is less specific than a prediction across a continuous range, but this could be a good thing when tuning or fitting a model because each permutation of potential inputs would be more likely to have been seen before a prediction is made.

\section{Conclusion}
In the future it would be interesting to compare an improved model to gambling lines to see how different the results are and whether there were any patterns to predicted results differing from betting lines and actual results. It could be possible, for example, that if there is a big enough discrepancy between a model's predictions and a gambling line that it would actually be worth betting. As it is, the model is not nearly accurate enough to be used to reliably predict results of sporting events, as it only out predicts random chance by twelve percent. As this was a first attempt at this sort of data analysis and the problem is quite complicated, this was a reasonable result, but still not a model to be used for practical applications. It would be interesting to see how much more of the model in the example from paper 2 could be recreated. If a more accurate predictive model like this was created, it could potentially be used by soccer teams in order to predict which matches are more likely to be won or lost so as to determine which matches would be best to rest key players. A match that is predicted to be a three goal win for your team, for example, would be a much better game to rest a key player than for a game predicted to be a draw. 

\section{Acknowledgements}
The author would like to thank Dr. Gregor von Laszewski for his support and guidance during this project and course in general.

\bibliographystyle{plain}
\bibliography{references}
\end{document}
