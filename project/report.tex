\documentclass[sigconf]{acmart}
\input{format/final}
\begin{document}

\title{Predictive Model For English Premier League Games}
\author{Josh Lipe-Melton}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{4400 E Sheffield Dr}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{jlipemel@umail.iu.edu}

\renewcommand{\shortauthors}{J. Lipe-Melton}

\begin{abstract}
We discuss a model for predicting the outcome of soccer matches based on the previous matches played by each team. The model we produce is based on a model discussed in a previous paper, which claims to predict match results extremely accurately based on the previous two meetings between the teams and the previous five matches of each of the teams. While the model we based the project on used a genetic tuning algorithm combined with a neural network, this was too complicated for our purposes. Instead, we first attempted to use a multivariate regression model. This model uses matrix algebra to generate coefficients based on the sample data given to it. These coefficients are then what is used to make predictions. The next model was a basic neural network model. This model creates different layers of perceptrons, which can solve more complicated problems than a single perceptron. Both of these models make use of python's sklearn package, and the code for our model is in the project.ipynb file. We evaluate both models and compare the predictive accuracy of each using a number of metrics. Potential uses for this type of model could include setting gambling lines or for the evaluation of the importance of certain games relative to one another. Furthermore, the analysis of the data could be used on any sets of data which are in the dataframe format. The neural network, multivariate regression model, and evaluation code is very flexible and could easily be used for other purposes.
\end{abstract}

\keywords{HID105, I523, sports, analytics, predictive, neural network}

\maketitle

\section{Introduction}
Prediction of sporting events is an extremely difficult problem due to the enormous number of factors involved and the unpredictability of those factors. While a lot of data about sports is generated, it is still extremely difficult to create models which account for every factor involved. In the model we attempt to imitate, a match's result is hypothesized to be predictable based on the last five matches each team has played and the last two matches between the teams. The model we imitated created a three layer neural network using these features, and was initiated with weights created by a genetic tuning algorithm. The model we use loads data on the English Premier League, England's highest league and arguably the best league in the world. Using this data, we create features for each match based on the previous games played by those teams. In this way, we attempt to circumvent far more complicated methods of analyzing sports such as per possession models or spatial recognition and player tracking software. Common thought among soccer players indicates that a team's 'form', or how well they have played in their last five matches, is a significant indicator of how well a team will do in their next match. Similarly, it seems to follow common sense that if team 1 has beaten team 2 the previous two times they have played, that team 1 is likely to beat team 2 again the next time they play. 

There are many supporting factors to the assumption that a team that has beaten another repeatedly will do so again. For one, teams in the premier league with more money consistently do significantly better than those with less money. According to Gerhards, ''success in national football championships is highly predictable. The market value of a team is by far the most important single predictor''. \cite{MarketValue} In comparison to variables such as diversity of a team or the amount of turnover in team personnel, market value was far more positively correlated to success. Furthermore, those teams that find success sell more jerseys and are featured on television more, thus generating even more wealth and ensuring that the wealth generated by soccer stays with the wealthier teams. 
These facts seem to support the statement that plugging the form, or last five results of each team, and the previous results between the two teams, into some model, we could expect to predict with some consistency the results of soccer matches. Market value implies consistent success of some teams over others, which would seem to indicate that the previous two meetings between two teams should consistently correlate to results. Given previous results, some of the unpredictability of sporting events in general is taken away. While random chance should still certainly be accounted for, we expect significant correlation between previous match results and future match results.

Although numerous other statistics are available that describe English Premier League soccer in more detail, we chose not to incorporate any other variables in our models. In general, the models discussed in paper 2 which performed well used fewer variables. The models that used a lot of different kinds of data were less effective. Therefore, the project model used only match results as data. 
In order to create models for predictive analytics, we used sklearn's python packages. The first is the multivariate linear regression model, which takes any number of variables and weights them according to their correlation to the true results. This model produces a continuous range of predictions. We also created a similar linear regression model using less features. Lastly, we created a neural network using the sklearn neural network package. This package takes an array of inputs, in this case match results, and produces layers of perceptrons, or 'neurons'. By combining multiple 'neurons' making use of stochastic gradient descent, more complicated problems and models can be represented than when using just one. Furthermore, ''The use of SGD In the neural network setting is motivated by the high cost of running back propagation over the full training set. SGD can overcome this cost and still lead to fast convergence.''\cite{StanfordSGD} Although sklearn offers various additional variables for tuning implementations of its neural network package, we chose not to use them in our code. This was due to a lack of experience tuning neural networks.

\section{Learning Models Examined From Paper 2}
In order to come up with our model, we examined models in paper 2 in order to develop a strategy to solve the complicated problem of predicting soccer games. We evaluated effectiveness and ease of implementation. Furthermore, we evaluated the different forms of data and models used in order to learn and implement the best parts of each model in our own model. This section is largely excerpts from paper 2.

\subsection{Expected Goals Model}
Arguably the most common method of predicting the results of soccer games is to create a prediction of the number of goals scored by each team . The result of subtracting these two numbers gives not only a prediction of which team will win, but an inherent level of confidence proportional to the difference of each predicted number of goals \cite{ExpectedGoals}. This model creates an ''expected goals value'' by predicting the number of shots and assigning each of these shots a value. These values are based on attributes such as angle from the goal, distance to the goal, body part used to take the shot, what type of approach was used to obtain the shot (dribble, short pass, long pass, etc.), and even the relevant FIFA video game ratings of the player taking the shot. Each value represents the predicted likelihood of scoring, with 0 being an impossible shot and 1 being a sure goal. By summing these values and incorporating the FIFA rating of the opposing goalkeeper, an expected goals value for a team is obtained. This model is able to predict the number of goals scored by each team about 20\% of the time. The correct result of the match was found about 56\% of the time \cite{ExpectedGoals}. While the data was extremely specific, the general assumption that a team's goals in a given match correlate to the quality of the shots the team gets plus the quality of the striker was extremely ineffective. \cite{paper2}

\subsection{Bivariate Expected Goals Model}
We drew some inspiration from this model discussed in paper 2: A flaw with the previous example of an expected goals model is that it accounted only for the attack team's ability in its goal predictions. Apart from the ability of the goalkeeper, there is no accounting for the defensive ability of an opponent in prediction of expected goals. In a different model, defensive ability and attacking ability are both incorporated. The authors of this method created their model based on the idea that the goals scored two competing soccer teams are negatively correlated with one another. By using a bivariate Poisson model for soccer data, the authors created predictions for the number of goals scored by each team in a given match, and therefore the results of each game\cite{BivariateExpected}. The covariates used in the bivariate Poisson regression model include: GDP per capita, population, home advantage, bookmaker's odds, market value, number of Champion's League players, number of club teammates, and the age of the coach. By running 1,000,000 simulations on the European Championships in 2016, predictions for each match were created, along with odds for each team to reach each round of the tournament. The odds of the model outperformed bookmakers' odds 42.22\% to 39.23\% in predictive accuracy\cite{BivariateExpected}. The authors used their model in placing equal bets on every bet in the tournament with the service that provided the most favorable odds to the outcome predicted by their model. In doing so, they obtained a return of 30.28\% after the tournament. The authors concluded that the scores of two soccer teams are indeed negatively correlated and that this is a sound notion to base a predictive model on \cite{BivariateExpected}. \cite{paper2}

From that model, we gained insights into how to make our model. First of all, the authors of that model gave an example that used a relatively simple to implement bivariate poisson model. Secondly, the authors of the model concluded that two team's goals were strongly negatively correlated. It is therefore important to take both teams into equal consideration. Finally, the authors of this model classified their results into simply home team win, home team loss, or draw, which provided an easy and effective way to evaluate the model. Our model is similarly able to predict a home win, home loss, or home tie, and the results are evaluated in this way as well.

\subsection{NCAA Analysis}
In college basketball, the committee that decides who gets into the NCAA tournament makes use of a ranking system called Ratings Percentage Index, or RPI. RPI weights .25 of a team's ranking on their win percentage, .5 on their opponents' win percentage, and .25 on their opponents' opponents' win percentage. \cite{RPI} This system is designed to encourage teams to schedule difficult opponents, as a large portion of the rankings is based on strength of schedule. This formula has significant influence on where teams are ranked. Unfortunately, ''the RPI lacks theoretical justification from a statistical standpoint.'' \cite{RPI} In general, it is believed that the model places too much emphasis on strength of schedule and not enough on performance. Attempts to utilize an improved version of this model have made an impact on seeding in college soccer and baseball as well. In these sports, wins are weighted to give more ranking points to an away win than a home win.\cite{RPI} These types of alterations, however, do not address the fact that 75\% of this ranking comes from a team's strength of schedule. This type of bias favors teams that are in strong conferences, even if they have poor records in their conference. \cite{paper2}

\subsection{Per Possession Analysis}
A proposed alternative to RPI is to use a ''per possession model,'' or a model that predicts outcomes using statistics that are used in the context of efficiency with possessions. For example, offensive efficiency is found by dividing points scored by possessions and defensive efficiency is found by dividing points allowed by possessions \cite{PerPossession}. These statistics are then used to calculate an offensive efficiency adjusted by the perceived strength of the opponent. Adjusted offensive efficiency, for example, is calculated by multiplying offensive efficiency by the average national offensive efficiency then dividing this number by the adjusted defensive efficiency of an opponent \cite{PerPossession}. By combining these adjusted efficiencies with other factors such as home court advantage, the authors made several models which created an estimation for ''win probability,'' which can in turn be used to predict individual match outcomes or create a ranking system. By using win probability, the study we examine created models based on decision trees, rule learners, artificial neural networks, naive Bayes, and ensemble learners. The neural network and naive Bayes models were the most effective models, both predicting outcomes with about 72\% accuracy\cite{PerPossession}. A surprising observation from the authors is that simpler models tend to work better than more complicated ones. Similarly, attempting to incorporate more features into the models tended to decrease predictive accuracy. The authors believe that there is a ''glass ceiling'' when it comes to accuracy predicting sporting events of around 74\% \cite{PerPossession}. Each of these models is unable to predict any individual season at a rate greater than 74\%\cite{PerPossession}. \cite{paper2}

\subsection{Fuzzy Neural Network Model}
In a paper 2, we discussed a method of prediction solely uses past results to predict future results. This model was extremely accurate and a under strong consideration for a model to base our project on. This section is an excerpt from \cite{paper2}:  In this method, a predictive model is based on the intuitive proposition that if team 1 has won their previous few games, team 2 has lost their previous few games, and team 1 has beaten team 2 the last two times they have played, team 1 will beat team 2 \cite{FuzzyModel}. The model proposed in this article assigns a value in the range [-5, 5] to the last five games played by each team as well as the last two games played between the two teams. The higher the number, the bigger the win. The lower the number, the bigger the loss. The predicted result of a game is a function of these numbers. Through a combination of a fuzzy logic table and a neural network algorithm, a result is predicted. First, the authors created a table with every possible value of x1-x12. Each of these combinations was then associated with a predicted result and a weight in the interval [0, 1] that indicated the confidence in the predicted result. These initial confidence intervals were then tuned. The predicted result is drawn from the range [Big loss (BL), Small loss (SL), Draw (D), Small win (SW), Big win (BW)] \cite{FuzzyModel}. Using a sample size of 1056 matches, the network assigned weights to the nodes in the neural network. The trained model was applied to 350 results from other seasons and was correct when predicting a big loss 91.4 percent of the time, a small loss 83.3 percent of the time, a draw 87 percent of the time, a small win 84 percent of the time, and a big win 94.6 percent of the time \cite{FuzzyModel}. The authors do cite flaws that come from not considering factors such as injured or suspended players, refereeing, or weather conditions \cite{FuzzyModel}. \cite{paper2}

Furthermore, this method's already impressive predictive accuracy could also be improved by taking into account strength of schedule, as a team that has narrowly won its last five games against very weak opponents would be favored against a team that has narrowly lost against very strong opponents. The machine learning techniques implemented in this study could have been improved by incorporating opponents' results into the model, giving more weight to wins against good teams. \cite{paper2} It would also be interesting to see whether using a continuous model would decrease the accuracy of predictions or give similar accuracy with more specificity than the fuzzy logic model. It seems possible that using the fuzzy logic model provides a neural network with more occurrences of samples that are similar to each other due to grouping results together, thereby providing a better prediction. In a continuous model, the features may be too varied for a neural network to pick up on without a greatly increased sample size.

After examining these models, we chose to create a multivariate linear regression model and a neural network. These models would use match results. The predictions would be continuously distributed, and would indicate the degree to which the home team would be expected to win, lose, or draw by. Python was chosen to implement these solutions due to the ease of use in machine learning and data analytics applications, as well as being the default language for this course. The Sklearn package was chosen due to the ease of implementation. Instead of having to construct a neural network or linear regression model from scratch, the implementation was straightforward and contained many ways to customize the models they provided. Our predictions will be evaluated based on percent of correct match results predicted, matches correctly predicted within 1 goal, matches correctly predicted to within half a goal, and mean squared error.

\section{Project Model}
In order to select the parameters for our model, we examined several models in paper 2. The most common type of predictive model for other sports was a per possession model. This model attempts to gauge the number of possessions each team will get, then gauge how efficient each team will be with their possessions. By multiplying the number of predicted possessions by the projected efficiency of the team, a prediction for the number of points scored by that team occurs. This means that a match prediction would be the difference of the predicted goals for each team. In soccer, this could be done with time of possession, a commonly tracked statistic. A model could for example predict that for each minute a team is expected to possess the ball, they are expected to score a certain number of goals. By incorporating the opposing team's predicted minutes of possession and predicted goals conceded, a prediction of goals scored and conceded could be obtained. 
However, after considering this type of model, we decided it had too many flaws to be implemented. Firstly, the model would not use a simple, readily available set of data. Secondly, the model would have to incorporate a greatly varying set of data. In paper 2, we concluded that ''simple inputs, especially those involving neural networks, provide the greatest accuracy in predicting the outcome of sporting events.'' \cite{paper2} Therefore, we decided to reject models that had several forms of data and stick to only match data.
It was also important to figure out what kind of data to use. In paper 2, models used features such as FIFA ratings, possession statistics, match results, and expected goals. We decided to move forward using match results due to the simplicity of that variable, as well as the abundance and ease of access for that data in a number of leagues. Ultimately, we chose to focus on just one league in order to attempt to keep the data consistent and to try to make predictions based on the highest level soccer possible. It could be an interesting topic to compare models' effectiveness in evaluating other leagues, but we chose to use match data from just the English Premier League.

In general, we attempted to imitate the model discussed in the section 'Fuzzy Neural Network Model'. We used match data from http://www.football-data.co.uk \cite{SoccerData}. The data includes numerous statistics about English Premier League soccer matches dating back to 1993, including the team names and goals scored by each team, which were the data we were interested in. In order to load the data from the .csv files included in the website into a usable format, we used panda's read csv function. Three years of the data was in an unreadable format for the csv loader and was skipped in the analysis, which included data from 2001-2003. We then narrowed the data down to the names of each team involved in each match and the number of goals scored by each team. We then created a function last5 to determine the last five matches the last team played, which returned the number of goals scored by the team minus the number of goals that had been scored on them over the course of those five games. This function partitioned off the dataframe with all results to include just the results which had occured before the match in question. Next, we used a boolean indexer in the dataframe to determine which rows contained the team name in either the home team or away team column. Each entry was added to a different list. That list was then negatively indexed to find the last five entries in the list, and each item was summed. This sum was what the function returned. We also created a function prevMeetings to determine the results of the last two times the teams played. This function took the data and the index of the match to be observed. Next, the names of the teams involved were found. Next, the data was slimmed to only include match results from the past. Next, we used a boolean indexer in the dataframe of past matches to determine which rows contained the home team name in either the home team column or the away team column, and the away team name in either the home team column or the away team column. We negatively indexed the dataframe produced to include only the last two results. Each of these results was summed.  In each of these functions, we used goal difference to represent each result. Goal difference was found by subtracting the number of goals allowed in a match by the home team from the number of goals scored in a match by the home team. We kept individual match results within the range[-4, 4] in order to prevent very large wins or losses from having too much influence on the statistics. A 7-0 win, therefore, counted the same as a 4-0 win, and a 7-0 win followed by five losses couldn't result in a positive goal difference for the team. Next, we created a function sampler, which used prevMeetings and last5 to turn each row in the data into an array of the features about each match that we wanted. We referred to the last5 of the home team as 'z1', the last5 of the away team as 'z2', and the previous two meetings of the teams as 'z3' and 'z4' respectively in order to more consistently imitate the model discussed in the Fuzzy Neural Network Model. Finally, we created a function that found the true results of each match by iterating through every match result and subtracting the away team's goals scored from the home team's goals scored, thus representing the ''true'' prediction. This model has the benefit of inherently giving value to the home team due to z1 always being the home team and z2 always being the away team. When two teams did not have previous results, z3 and z4 were entered as 0 and 0 so as not to affect the prediction either way. Because of this, we trimmed the first 250 results out of the data so as not to have too many z3 and z4 data points equal to 0. When a team did not have five previous matches in the data, last5 returned a -5, as this typically indicates a team recently promoted to the league and therefore the team would not be expected to find much success. These functions slightly differed from the more complicated model we were imitating, as this used the last five results from each team as individual features in the first input layer of a neural network and the previous two meetings as input nodes in the second layer of a neural network. Furthermore, the model we were imitating used fuzzy logic to model the problem as a classification problem, using big loss, small loss, draw, big win, and small win as the classifications. Our model, however, attempts to create a continuous solution. In order to do so, we take the results of sampler as our sample data used for prediction and the output of another function, results, as our true data. Sklearn's multivariate linear regression model uses matrix algebra in order to create coefficients for each variable in the sample X. Each coefficient indicates the strength of the correlation between the variable in X and the actual result. Therefore, the coefficient is the weight which the variable is multiplied by when using the model to predict. Using sklearn's model, we fitted the sample data to the results and created an array of predictions, which we then compared to the true results.  We also used sklearn's neuralnetwork package to create a MLP Regressor neural network with the hidden layer sizes attribute set to 50, which we found to produce the smallest mean squared error. In order to reduce the bias towards z1 and z2, which are typically bigger in absolute value than z3 and z4, the data was scaled during preprocessing for this model. Next, the neural network fit the scaled data to the true results. Finally, evaluation of the model was done based on mean squared error between predictions and true results and percentages of correct predictions or predictions that were within a certain range of the true result. In our model, a correct prediction was classified as simply predicting within the same category as the result, with the categories being less than -.5, greater than .5, or in between .5 and -.5 goal difference, each representing a draw, home win, or home loss respectively. We also tested whether each prediction was within .5 or 1 of the true result. These predictions represent the expected goal difference of the home team, meaning the predicted value of the home team's goals scored minus the away team's goals scored. After the prediction sets for each model were created, we changed the mean of the data to fit the mean goal difference of the results, which was just over 0.4. We also changed the standard deviation to match the standard deviation of the results.


\section{Evaluation}
\subsection{Efficiency}
Extraction of the data was relatively fast. The retrieveEPL function extracts 7832 rows of a dataframe relatively quickly. The last5 function is slow due to running 7832 times and checking a large portion of the dataframe for previous results each time. The sampler function is by far the slowest to run due to the large number of comparisons and indexes it has to do. Running last5 and prevMeetings on each row of the dataframe is less than quadratic time, but still ends up being extremely costly computationally. The results function runs in linear time, which is optimal. Finally, the models are fitted to the data extremely quickly as well.

\subsection{Prediction Performance}
The performance of the predictions was far less effective than the fuzzy neural network model we attempted to replicate. This was to be expected, however, as our model was simply a more basic version of the other model. In order to evaluate our model, we measure the mean squared error between the actual results and the predicted results of both the multivariate linear regression model and the neural network. Each had an almost identical mean squared error, with the neural network scoring 2.851 and the linear regression model scoring 2.868. Each model also had nearly identical proportions of games predicted within .5 of the correct result (.264 for the neural network and .263 for the multivariate linear regression model), games predicted within 1 of the correct result (.49 for both models), draws correctly predicted (.147 for the neural network and .144 for the multivariate linear regression model), home wins correctly predicted (.249 for the neural network and .255 for the multivariate linear regression model), home losses correctly predicted (.020 for the neural network and .019 for the multivariate linear regression model), and percent total correct predictions (.417 for the neural network and .419 for the multivariate linear regression model). The effect of z1 and z2 was as would be expected: z1 was a positive coefficient for the regressino model and z2 was negative. This indicates that the home team was favored, which was reflected in the mean value in both the prediction and true results sets being about 0.4. It was interesting to note, however, that the z3 and z4 features had almost no effect on the accuracy of the predictions. The linear regression model's coefficient for these two features was almost 0. This is extremely counter intuitive and could be a result of inserting 0 for z3 and z4 at times where no previous results could be found, although it seems that these should still be significant features for prediction. Both models' prediction sets' standard deviation was far lower than the actual results, which could be a significant factor in the mean squared error. After hypothesizing that this may have increased the number of home losses predicted correctly, we tried increasing the standard deviation. After subtracting the mean of each array from each element in the array, then multiplying each value by 1.76, the standard deviation of the true results, and adding the mean back to each element, the percent of correct results predicted increased to 45.00 and 45.50 percent for the multivariate linear regression model and neural network model respectively. Doing this, however, decreased the number of results predicted within .5 goals and 1 goal by about 7 percent for the multivariate linear regression model and by about 8 percent for the neural network model. This is most likely due to the fact that a large portion of soccer games end with a goal difference within 1 and -1, so pushing predictions farther from the mean reduces the number of predictions close to this range. The highest final predictive accuracy obtained by any of the models, therefore, was 45.5 percent. This compares favorably to the bivariate poisson distribution model discussed earlier in the paper, which claims ''The odds of the model outperformedbookmakers’ odds 42.22 percent to 39.23 percent in predictive accuracy'' \cite{BivariateExpected}. Therefore, it appears our model has predictive accuracy significantly greater than some odds or models.

\subsection{Limitations}
In retrospect, it seems that the models' biggest flaws are both their lack of ability to incorporate the z3 and z4 features into their prediction. Going into the project, I had hypothesized that this should be the biggest indicator of which team would win, regardless of their play during their last five matches. This hypothesis was supported by the fuzzy neural network model we attempted to imitate as well. Furthermore, the repeated success of a handful of teams over the rest of the league would seem to indicate that a team that beats another team multiple times would continue to do so. This is due in large part to the fact that certain teams have far more money than others to spend on players, facilities, etc., and this does not typically change from year to year. Neither model in this project seemed to indicate that previous matches between teams had a significant affect on the match prediction. Common sense would therefore seem to indicate significant issues with the implementation of the model in our project. In future implementations, we could try a different way to handle cases where there are not two previous meetings between the teams. We could, for example, give the benefit of the doubt to the team that has been in the league the longest, as we did with the last5 function. It may also be that the hole in our data in the early two thousands could be significantly affecting that feature. The csv files for those years were significantly different and could not be processed with the same function used to load the data from the other years. This is another problem with our model, as it is based on data that is incomplete and skips three years. The model we attempted to imitate had a much smaller sample size (about 1000 compared to about 8000 for ours), but presumably had accurate data points for each sample. Finally, more work with tuning neural networks would be extremely helpful, as this is a first attempt at any sort of data analysis to this degree. More experience with setting up models and more knowledge of advanced statistics would presumably greatly strengthen a model such as this. It may also be helpful to take each season independently, as teams undergo significant change over the course of the offseason. In the model in this project, a team's first game of the season is predicted using the last five games from last season, which could have been a very different set of players. In the future, it could be useful to run comparisons between our project model and a model that ignored the first five games of the season for each team so as to ''get a feel'' for the way a team starts out the year instead of assuming they will pick up right where they left off from the season before. Further improvements could take into account other factors such as injuries, suspensions, refereeing or weather. Clearly, we were unable to replicate all facets of the other model. The genetic tuning was extremely complicated and tough to figure out, and the neural network had more sophisticated layers and tuning. Our sample size was greater, but the data was arguably less precise due to not having previous results for every game. Furthermore, breaking results down into categories using fuzzy logic could potentially enable the model to make more accurate predictions. The fuzzy logic is less specific than a prediction across a continuous range, but this could be a good thing when tuning or fitting a model because each permutation of potential inputs would be more likely to have been seen before a prediction is made. 
Another potential improvement could be to simply include more features. As indicated in the introduction, the financial value of a team is a significant indicator of a team's success, particularly in the premier league. According to \cite{TransferMarkt}, Chelsea is worth 631 million Euros, while Huddersfield Town is worth just 58 million. This great divide in value is seen consistently across top European leagues and could be a significant indicator of the results of matches due to the importance of being able to buy the best players. While this statistic could be partially accounted for in the previous two meetings between teams, it could be valuable to include it as its own feature in the predictive model. A potential problem would be the skyrocketing value of clubs over the last twenty years, as it would be difficult to scale the data appropriately before fitting the model.
Another feature to consider would be to augment the last five played and previous two meetings features in this model by taking into account the strength of schedule. For example, beating a team that was on a win streak would be more valuable than beating a team that had lost its last five games. This could be incorporated as a multiplier in the last5 and prevMeetings functions. In this way, more information could be included in the predictive model.

\section{Conclusion}
In the future it would be interesting to compare an improved model to gambling lines to see how different the results are and whether there were any patterns to predicted results differing from betting lines and actual results. It could be possible, for example, that if there is a big enough discrepancy between a model's predictions and a gambling line that it would actually be worth betting. As it is, the model is not nearly accurate enough to be used to reliably predict results of sporting events, as it only out predicts random chance by twelve percent. An improved model could potentially be used to set betting lines or to inform how to beat betting lines. As this was a first attempt at this sort of data analysis and the problem is quite complicated, this was a reasonable result. However, this is again not a model to be used for practical applications. It would be interesting to see how much more of the model in the example from paper 2 could be recreated. If a more accurate predictive model like this was created, it could potentially be used by soccer teams in order to predict which matches are more likely to be won or lost so as to determine which matches would be best to rest key players. A match that is predicted to be a three goal win for your team, for example, would be a much better game to rest a key player than a game predicted to be a draw. The tactics of a team could change based on the prediction, such as a coach playing more defensively in a game their team was predicted to lose, and instead bank on tying in order to get some sort of positive result out of it. Furthermore, the model could be applied to other sports quite easily. By properly scaling data, data from sports such as football and basketball could put into the model and used in the same way. If the range for the goal difference of each game was changed, the theory behind the model could be tested for other sports as well. A future project could be to examine the difference in the correlation of past results in basketball or football versus soccer.
Another potential change to this model would be to predict the number of goals each team will score instead of only predicting the goal difference. The model could be quite similar. Instead of the last5 function returning only the goal difference, it could return a list of lists, each of which stores the number of goals scored and the number of goals conceded for each of the last five matches. Next, the prevMeetings function would change to the same format. The sampler function could return a prediction for the number of goals scored and the number of goals conceded by each team using a regression model or neural network. Next, these predictions would be fed into another regression model or neural network that predicted the number of goals scored or conceded by either team. These second layer models would combine a team's goals scored prediction and the opposing team's goals conceded prediction in order to predict the number of goals scored. Similarly, they would combine a team's goals conceded prediction and the opposing team's goals scored prediction in order to predict the number of goals scored. Both a multivariate linear regression model and a neural network could be used for this format. These predictions could give a more accurate representation of a game and incorporate some of the variables that a ''per possession'' model would use, while still using the same data as before, albeit in a slightly different way. By diversifying what the model is able to incorporate but still using simple and accurate data, the new model could obtain the best qualities of the previous models described without adding significant computational time. Each function might be expected to take longer, but these changes would not alter the big-O worst case time complexity of the model in general. The advantages of this sort of model's prediction is that it could be used to make more specific types of gambling lines, such as over/unders. Furthermore, it could better inform a coach on tactical decisions about how aggressive or defensive to align his team.
The models described in this paper could make a great starting point for predictive modeling of any kind, as the models included are extremely flexible. Although the majority of the work ended up being actually finding, parsing, and formatting the data correctly, the methods used to analyze the data would work with any big sets of data in a dataframe format.

\section{Acknowledgements}
The author would like to thank Juliette Zerick for their help throughout this course. Furthermore, I would like to thank Dr. Gregor von Laszewski for the tireless reformatting of papers, and catching and fixing the numerous errors that I and others in this course have made. 

\bibliographystyle{ACM-Reference-Format}
\bibliography{report}
\end{document}
